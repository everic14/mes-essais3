{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mlittmancs/great_courses_ml/blob/master/L14qs.ipynb","timestamp":1695486298257}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kilKsIChiW0G"},"source":["We showed that the VGG-16 network can be used to encode images it was not trained on---a cheese grater and a foot file---as vectors that are perfectly recognized by K nearest neighbors. What do you think would happen if we used nearest neighbors (or naive Bayes or a neural network) classifier on the raw vectors?"]},{"cell_type":"markdown","metadata":{"id":"B0wL-7mKuLue"},"source":["We'll download addtional images from GitHub below"]},{"cell_type":"code","metadata":{"id":"8XdXSJxHvOBP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b154204-e8dd-48f9-b808-8fc3cc24fe40"},"source":["!wget https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/tools.zip\n","!unzip tools.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-07 15:45:36--  https://github.com/mlittmancs/great_courses_ml/raw/master/imgs/tools.zip\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/imgs/tools.zip [following]\n","--2022-11-07 15:45:37--  https://raw.githubusercontent.com/mlittmancs/great_courses_ml/master/imgs/tools.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2502460 (2.4M) [application/zip]\n","Saving to: ‘tools.zip.3’\n","\n","tools.zip.3         100%[===================>]   2.39M  --.-KB/s    in 0.06s   \n","\n","2022-11-07 15:45:37 (37.8 MB/s) - ‘tools.zip.3’ saved [2502460/2502460]\n","\n","Archive:  tools.zip\n","replace cg01.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: cg01.jpeg               \n","  inflating: cg02.jpeg               \n","  inflating: cg03.jpeg               \n","  inflating: cg04.jpeg               \n","  inflating: cg05.jpeg               \n","  inflating: cg06.jpeg               \n","  inflating: cg07.jpeg               \n","  inflating: cg08.jpeg               \n","  inflating: cg09.jpeg               \n","  inflating: cg10.jpeg               \n","  inflating: ff01.jpeg               \n","  inflating: ff02.jpeg               \n","  inflating: ff03.jpeg               \n","  inflating: ff04.jpeg               \n","  inflating: ff05.jpeg               \n","  inflating: ff06.jpeg               \n","  inflating: ff07.jpeg               \n","  inflating: ff08.jpeg               \n","  inflating: ff09.jpeg               \n","  inflating: ff10.jpeg               \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QYlnJ--13Alh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"_9BlFXny3CFT"}},{"cell_type":"markdown","metadata":{"id":"GIvRfL5QaTrv"},"source":["Loading the raw image vectors as a dataset."]},{"cell_type":"code","metadata":{"id":"bQ1GesmY9mDf"},"source":["# get images\n","from PIL import Image\n","from IPython.display import display\n","from tensorflow import keras\n","\n","# from keras.preprocessing import image\n","from keras.applications.vgg16 import preprocess_input\n","import numpy as np\n","\n","dat = []\n","labs = []\n","imgs = []\n","imgflist = [\"cg01\", \"cg02\", \"cg03\", \"cg04\", \"cg05\", \"cg06\", \"cg07\", \"cg08\", \"cg09\", \"cg10\",\n","           \"ff01\", \"ff02\", \"ff03\", \"ff04\", \"ff05\", \"ff06\", \"ff07\", \"ff08\", \"ff09\", \"ff10\"]\n","for imgf in imgflist:\n","    img = keras.utils.load_img(imgf+\".jpeg\", target_size=(224,224))\n","    imgs.append(img)\n","    img_arr = np.expand_dims(keras.utils.img_to_array(img), axis=0)\n","#    x = preprocess_input(img_arr)\n","#    preds = model2.predict(x)\n","    dat.append(img_arr.flatten())\n","    labs.append(imgf[0:2] == 'ff')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pj_J81yTbiwc"},"source":["Dividing the data into training and testing data."]},{"cell_type":"code","metadata":{"id":"4plqRVQrdWIQ"},"source":["train = [i for i in range(0,5)]+[i for i in range(10,15)]\n","test = [i for i in range(5,10)]+[i for i in range(15,20)]\n","\n","X_train = [dat[inst] for inst in train]\n","y_train = [labs[inst] for inst in train]\n","X_test =  [dat[inst] for inst in test]\n","y_test =  [labs[inst] for inst in test]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nL0qTNbHihsq"},"source":["Train using Naive Bayes."]},{"cell_type":"code","metadata":{"id":"W_rkqAnbdcLm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"12c013d5-e340-43f9-91be-3d9a18143523"},"source":["from sklearn.naive_bayes import MultinomialNB\n","\n","clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n","score = clf.score(X_test, y_test)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5\n"]}]},{"cell_type":"markdown","metadata":{"id":"afJ7zkhrij1a"},"source":["Train using nearest neighbor."]},{"cell_type":"code","metadata":{"id":"OD7MzdFcdiAt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd1dff9e-ceb3-4763-a3b6-29ff20ac15e1"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n","clf.fit(X_train, y_train)\n","score = clf.score(X_test, y_test)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"qa09vQuVimj8"},"source":["Train using neural network."]},{"cell_type":"code","metadata":{"id":"iz95vOMDfN8U","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d641cc1-da11-44ab-8bd2-d04a6659a646"},"source":["from sklearn.neural_network import MLPClassifier\n","\n","clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n","clf.fit(X_train, y_train)\n","score = clf.score(X_test, y_test)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5\n"]}]},{"cell_type":"markdown","metadata":{"id":"J5fVZ_TlggDT"},"source":["For comparison, here are those same algorithms using the representation that comes from VGG16."]},{"cell_type":"code","metadata":{"id":"o9acgp2_ftSf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6eab4d8a-d941-47e9-d380-f6824da73178"},"source":["!pip install keras=='2.3.1'\n","from keras.models import Model\n","from keras.layers import Dense,Flatten\n","from keras.applications import vgg16\n","from keras import backend as K\n","\n","model = vgg16.VGG16(weights='imagenet', include_top=True)\n","\n","model2 = Model(model.input, model.layers[-2].output)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (2.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (6.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.6)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.7.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gIko-YKGiH-s"},"source":["Gather the vectors."]},{"cell_type":"code","metadata":{"id":"eMdt2G2Agy-K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ca77a74-7f8c-49bd-ae82-1a09cb90f8aa"},"source":["datraw = dat\n","dat = []\n","\n","for img in imgs:\n","    img_arr = np.expand_dims(keras.utils.img_to_array(img), axis=0)\n","    x = preprocess_input(img_arr)\n","    preds = model2.predict(x)\n","    dat.append(preds[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7ff86d63d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7ff86d63d4d0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 752ms/step\n","1/1 [==============================] - 1s 804ms/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 1s/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"EJ3wimixiKY-"},"source":["Make a new training/testing set."]},{"cell_type":"code","metadata":{"id":"2dgwO3Wwho1C"},"source":["train = [i for i in range(0,5)]+[i for i in range(10,15)]\n","test = [i for i in range(5,10)]+[i for i in range(15,20)]\n","\n","X_train = [dat[inst] for inst in train]\n","y_train = [labs[inst] for inst in train]\n","X_test =  [dat[inst] for inst in test]\n","y_test =  [labs[inst] for inst in test]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Naive Bayes."],"metadata":{"id":"ey2EuMUyw-i1"}},{"cell_type":"code","metadata":{"id":"xY3KmE9ThOZu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0ec5244-2ee9-4ae0-f858-ca7c36cf3a67"},"source":["from sklearn.naive_bayes import MultinomialNB\n","\n","clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n","score = clf.score(X_test, y_test)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"9om5O0fYiPF8"},"source":["Nearest neighbors."]},{"cell_type":"code","metadata":{"id":"6sO7EQGrhSdd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"30ae756c-a844-41eb-e634-690a12aec81f"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","clf = KNeighborsClassifier(n_neighbors=1,metric=\"cosine\")\n","clf.fit(X_train, y_train)\n","score = clf.score(X_test, y_test)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"ETy5W-4diRoB"},"source":["And neural networks, all perfect."]},{"cell_type":"code","metadata":{"id":"UCysBL8HhUel","colab":{"base_uri":"https://localhost:8080/"},"outputId":"54d76330-a4a6-49b8-8703-99ccdfaadd3f"},"source":["from sklearn.neural_network import MLPClassifier\n","\n","clf = MLPClassifier(hidden_layer_sizes=[100, 100, 100, 100, 100], max_iter = 10000)\n","clf.fit(X_train, y_train)\n","score = clf.score(X_test, y_test)\n","\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n"]}]}]}